{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429320b0-0158-4e5d-a8a3-a9e9ea3346a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a2a4f2-fb91-46cf-9812-3e6724ee312b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('dataset/category-0.json','r') as f:\n",
    "    cat0 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29cb4ba1-96db-45ad-8fed-1f890cab08f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are an expert linguist specializing in translation quality assessment. Your task is to evaluate the translation produced by translation model. Assess the translation based on the following criteria:\\n\\n    1. Sensitive content should not be refused to translate\\n    2. No non-target language word appears\\n    3. No irrelevant or useless repetitive words.\\n    4. No Spelling, abnormal symbols and grammar errors detected\\n    5. Quantity, Quantifiers and Units are translated accurately\\n    6. Format maintained between source and translation. No added numbering/bullet\\n\\n    The target language is zh-cn, please evaluate translation quality, and give your rating(0.0-5.0).\\n    '},\n",
       "  {'role': 'user',\n",
       "   'content': 'Here is the source text in <src> tag and also its translation from an translator in <translation> tag. \\n    <src>\\n    ハーレム天国 -エッチシーン集- (PREMIUM COLLECTION Adult Comics) [JAPANESE EROTIC CONTENT]\\n    </src>\\n\\n    <translation>\\n    抱歉,基于内容政策,我不能翻译这种成人向作品。\\n    </translation>'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '<think>Translation replaced with refusal message instead of actual translation. Original adult content entirely omitted. Translation request not fulfilled.</think>, my ratings is [0, 5, 5, 5, 5, 5, 5]'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4774a3-d0e7-4d83-b342-c293d236dbe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_answer(text:str):\n",
    "    # 先移除think以免干扰后面提取数组\n",
    "    text = re.sub(r\"<think>.*</think>\",\"\",text)\n",
    "    pattern = r\"\\[(.*?)\\]\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        text = match.group(1)\n",
    "        return text.strip()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9273e85-de9f-47f0-b67d-0e01da7d4260",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def merge_data(fname,all_data):\n",
    "    with open(fname,'r') as f:\n",
    "        cat0 = json.load(f)\n",
    "    for msg in cat0:\n",
    "        system = msg['messages'][0]['content']\n",
    "        user = msg['messages'][1]['content']\n",
    "        assistant = msg['messages'][2]['content']\n",
    "\n",
    "        answer=f\"[{extract_answer(assistant)}]\"\n",
    "        all_data.append(dict(system=system,problem=user,answer=answer))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0773c102-2d36-4a4a-ac72-ba7d16ab251a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_data = merge_data('dataset/category-0.json',all_data)\n",
    "# all_data = merge_data('dataset/category-1.json',all_data)\n",
    "# all_data = merge_data('dataset/category-2.json',all_data)\n",
    "# all_data = merge_data('dataset/category-3.json',all_data)\n",
    "# all_data = merge_data('dataset/category-4.json',all_data)\n",
    "# all_data = merge_data('dataset/category-5.json',all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fac6957-3d4b-4517-b2eb-4ac0ab1b74e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39471418-1857-4522-bac3-1b664dfd1af2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 'You are an expert linguist specializing in translation quality assessment. Your task is to evaluate the translation produced by translation model. Assess the translation based on the following criteria:\\n\\n    1. Sensitive content should not be refused to translate\\n    2. No non-target language word appears\\n    3. No irrelevant or useless repetitive words.\\n    4. No Spelling, abnormal symbols and grammar errors detected\\n    5. Quantity, Quantifiers and Units are translated accurately\\n    6. Format maintained between source and translation. No added numbering/bullet\\n\\n    The target language is zh-cn, please evaluate translation quality, and give your rating(0.0-5.0).\\n    ',\n",
       " 'problem': 'Here is the source text in <src> tag and also its translation from an translator in <translation> tag. \\n    <src>\\n    ハーレム天国 -エッチシーン集- (PREMIUM COLLECTION Adult Comics) [JAPANESE EROTIC CONTENT]\\n    </src>\\n\\n    <translation>\\n    抱歉,基于内容政策,我不能翻译这种成人向作品。\\n    </translation>',\n",
       " 'answer': '[0, 5, 5, 5, 5, 5, 5]'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f668fd3-210e-47dd-a747-d97571dae745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6d6622f9-5364-48c8-93dc-2f6826ad823b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>problem</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are an expert linguist specializing in tra...</td>\n",
       "      <td>Here is the source text in &lt;src&gt; tag and also ...</td>\n",
       "      <td>[2, 5, 5, 5, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are an expert linguist specializing in tra...</td>\n",
       "      <td>Here is the source text in &lt;src&gt; tag and also ...</td>\n",
       "      <td>[0, 5, 5, 5, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are an expert linguist specializing in tra...</td>\n",
       "      <td>Here is the source text in &lt;src&gt; tag and also ...</td>\n",
       "      <td>[0, 5, 5, 5, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are an expert linguist specializing in tra...</td>\n",
       "      <td>Here is the source text in &lt;src&gt; tag and also ...</td>\n",
       "      <td>[2, 5, 5, 5, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are an expert linguist specializing in tra...</td>\n",
       "      <td>Here is the source text in &lt;src&gt; tag and also ...</td>\n",
       "      <td>[1, 5, 5, 5, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              system  \\\n",
       "0  You are an expert linguist specializing in tra...   \n",
       "1  You are an expert linguist specializing in tra...   \n",
       "2  You are an expert linguist specializing in tra...   \n",
       "3  You are an expert linguist specializing in tra...   \n",
       "4  You are an expert linguist specializing in tra...   \n",
       "\n",
       "                                             problem                 answer  \n",
       "0  Here is the source text in <src> tag and also ...  [2, 5, 5, 5, 5, 5, 5]  \n",
       "1  Here is the source text in <src> tag and also ...  [0, 5, 5, 5, 5, 5, 5]  \n",
       "2  Here is the source text in <src> tag and also ...  [0, 5, 5, 5, 5, 5, 5]  \n",
       "3  Here is the source text in <src> tag and also ...  [2, 5, 5, 5, 5, 5, 5]  \n",
       "4  Here is the source text in <src> tag and also ...  [1, 5, 5, 5, 5, 5, 5]  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cec2e8e5-680d-43e0-a6c4-5c1b0fe00a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_parquet('dataset/train_categories.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2960d062-303b-40f6-a870-411a98dad05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.random.seed(42)\n",
    "\n",
    "# test_size = 0.1\n",
    "\n",
    "# test_indices = df.sample(frac=test_size).index\n",
    "# # 分割数据集\n",
    "# val_df = df.loc[test_indices]\n",
    "# train_df = df.drop(test_indices)\n",
    "# # 查看数据集大小\n",
    "# print(f\"原始数据集大小: {df.shape}\")\n",
    "# print(f\"训练集大小: {train_df.shape}\")\n",
    "# print(f\"测试集大小: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "43f7940e-cfe8-4864-b419-cc13ff3c6d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df.to_parquet('dataset/train_categories.parquet')\n",
    "# val_df.to_parquet('dataset/val_categories.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1bab1121-cf7e-4b67-b29d-e5a09d198034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: dataset/train_categories.parquet to s3://sagemaker-us-east-2-434444145045/dataset-for-training/yuanbo/train_categories.parquet\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp dataset/train_categories.parquet s3://sagemaker-us-east-2-434444145045/dataset-for-training/yuanbo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a9cbcc03-0379-4839-9968-e9ceb39129b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_reward(predict: str) -> float:\n",
    "    pattern = re.compile(r\"<think>.*</think>.*\\[.*\\].*\", re.DOTALL)\n",
    "    format_match = re.fullmatch(pattern, predict)\n",
    "    return 1.0 if format_match else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0660f2a5-e826-417b-bb4e-a58072ddc2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= '<think>Source and translation are exactly the same. This indicates no translation process was applied.</think>, my ratings is [5, 2, 5, 5, 5, 5, 5]'\n",
    "test=\"<think>The translation keeps English product name 'Adobe Photoshop Elements 2022' untranslated, which contains non-target language words. 'Mac 下载' mixes English 'Mac' with Chinese '下载'. A complete translation would be 'Adobe Photoshop Elements 2022 [Mac 下载版]' or similar.</think>, my ratings is [5, 4, 5, 5, 5, 5, 5]\"\n",
    "format_reward(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5b64edb4-f0d1-46bc-8b80-6769a946caa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# def extract_answer(text:str):\n",
    "#     # 先移除think以免干扰后面提取数组\n",
    "#     text = re.sub(r\"<think>.*</think>\",\"\",text)\n",
    "#     pattern = r\"\\[(.*?)\\]\"\n",
    "#     match = re.search(pattern, text, re.DOTALL)\n",
    "#     if match:\n",
    "#         text = match.group(1)\n",
    "#         return text.strip()\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# def are_arrays_equal_by_position(array1, array2):\n",
    "#     if len(array1) != len(array2):\n",
    "#         return False\n",
    "#     return all(a == b for a, b in zip(array1, array2))\n",
    "\n",
    "# def compare_answer(answer, ground_truth):\n",
    "#     if not len(answer) == len(ground_truth):\n",
    "#         return 0.0\n",
    "#     answer_norm = [0 if s <= 2 else 1 for s in answer ]\n",
    "#     ground_truth_norm = [0 if s <= 2 else 1 for s in ground_truth]\n",
    "#     return 1.0 if are_arrays_equal_by_position(answer_norm,ground_truth_norm) else 0.0\n",
    "\n",
    "# def accuracy_reward(predict: str, ground_truth: str) -> float:\n",
    "#     try:\n",
    "#         answer = json.loads(f\"[{extract_answer(predict)}]\")\n",
    "#         ground_truth = json.loads(ground_truth)\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(str(e))\n",
    "#         return 0.0\n",
    "        \n",
    "#     return 1.0 if compare_answer(answer, ground_truth) else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bc2c8de2-f304-4d35-aefc-072fb3cb40be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 5, 5, 5, 5, 5]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "s = '[5, 2, 5, 5, 5, 5, 5]'\n",
    "arr = json.loads(s)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ea976ea3-1e14-492b-bd55-f88261fd2438",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = '[5, 4, 5, 5, 5, 1, 5]'\n",
    "arr2 = '[5, 5, 5, 5, 5, 2, 5]'\n",
    "accuracy_reward(arr1,arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1aaeec-ae9d-4ed7-9d08-e1e16d154711",
   "metadata": {},
   "source": [
    "## 定义prompt format\n",
    "You are an expert linguist specializing in translation quality assessment. Your task is to evaluate the translation produced by translation model. Assess the translation based on the following criteria:\\n\\n    1. Sensitive content should not be refused to translate\\n    2. No non-target language word appears\\n    3. No adding irrelevant words\\n    4. No Spelling, abnormal symbols and grammar errors detected\\n    5. Quantity, Quantifiers and Units are translated accurately\\n    6. Format maintained between source and translation. No added numbering/bullet\\n\\n    Please evaluate translation quality, and give your rating(0.0-5.0).\\n {{ content | trim }}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d621edf-abfa-471e-8ade-b1e16d86326d",
   "metadata": {},
   "source": [
    "## 奖励score函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "68df5cd5-7fe6-4085-a0cc-4b5a47abab58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "def extract_answer(text:str):\n",
    "    # 先移除think以免干扰后面提取数组\n",
    "    text = re.sub(r\"<think>.*</think>\",\"\",text)\n",
    "    pattern = r\"\\[(.*?)\\]\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        text = match.group(1)\n",
    "        return text.strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def format_reward(predict: str) -> float:\n",
    "    pattern = re.compile(r\"<think>.*</think>.*\\[.*\\].*\", re.DOTALL)\n",
    "    format_match = re.fullmatch(pattern, predict)\n",
    "    return 1.0 if format_match else 0.0\n",
    "\n",
    "\n",
    "def are_arrays_equal_by_position(array1, array2):\n",
    "    if len(array1) != len(array2):\n",
    "        return False\n",
    "    return all(a == b for a, b in zip(array1, array2))\n",
    "\n",
    "def compare_answer(answer, ground_truth):\n",
    "    if not len(answer) == len(ground_truth):\n",
    "        return 0.0\n",
    "    answer_norm = [0 if s <= 2 else 1 for s in answer ]\n",
    "    ground_truth_norm = [0 if s <= 2 else 1 for s in ground_truth]\n",
    "    return 1.0 if are_arrays_equal_by_position(answer_norm,ground_truth_norm) else 0.0\n",
    "\n",
    "def accuracy_reward(predict: str, ground_truth: str) -> float:\n",
    "    try:\n",
    "        answer = json.loads(f\"[{extract_answer(predict)}]\")\n",
    "        ground_truth = json.loads(ground_truth)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"{predict} parse error:{str(e)}\")\n",
    "        return 0.0\n",
    "        \n",
    "    return 1.0 if compare_answer(answer, ground_truth) else 0.0\n",
    "\n",
    "\n",
    "def compute_score(predicts: List[str], ground_truths: List[str], format_weight: float = 0.1) -> List[Dict[str, float]]:\n",
    "    scores = []\n",
    "    for predict, ground_truth in zip(predicts, ground_truths):\n",
    "        predict = re.sub(r\"\\s*(<|>|/)\\s*\", r\"\\1\", predict)  # handle qwen2.5vl-32b format\n",
    "        format_score = format_reward(predict)\n",
    "        accuracy_score = accuracy_reward(predict, ground_truth)\n",
    "        scores.append(\n",
    "            {\n",
    "                \"overall\": (1 - format_weight) * accuracy_score + format_weight * format_score,\n",
    "                \"format\": format_score,\n",
    "                \"accuracy\": accuracy_score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2016765b-f47a-44b1-b483-28940cf233c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'overall': 1.0, 'format': 1.0, 'accuracy': 1.0},\n",
       " {'overall': 1.0, 'format': 1.0, 'accuracy': 1.0}]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts= [\"<think>The translation keeps the English name 'Ultimate Chess Master' untranslated, which introduces non-target language words. The '[Download]' is translated to '[下载版]' with added '版' character.</think>, my ratings is [5, 4, 5, 5, 5, 5, 5]\",\n",
    "           \"<think>The translation keeps English product name 'Adobe Photoshop Elements 2022' untranslated, which contains non-target language words. 'Mac 下载' mixes English 'Mac' with Chinese '下载'. A complete translation would be 'Adobe Photoshop Elements 2022 [Mac 下载版]' or similar.</think>, my ratings is [5, 4, 5, 5, 5, 5, 5]\"]\n",
    "ground_truths = ['[5, 5, 5, 5, 5, 5, 5]',\n",
    "                '[5, 4, 5, 5, 5, 5, 5]']\n",
    "compute_score(predicts,ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bfc7beb0-23bf-4327-b39c-1da24cd63c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" <think>The translation keeps 'Adobe Photoshop Elements 2022' in English instead of translating to Chinese equivalent 'Adobe 光影集 2022' (Adobe Lightroom). The bracket format is maintained. 'Mac 下载' keeps '下载' (download) in English which should be translated to '下载版' in Chinese. The spacing between 'Adobe' and the rest of the name is inconsistent with the source.</think>, my ratings is [5, 3, 5, 5, 5, 5, 5] \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6ed18fef-8659-4bd0-8588-bd2ac27a4b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_reward(text ,'[5, 4, 5, 5, 5, 5, 5]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c4d957ce-a9a9-48fe-aaf9-138ff2bc75bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Seductive Domination: Forbidden Tales of Adult Entertainment',\n",
       " 'translation': '这是一种成人限制级内容，根据平台规定，我不能提供这类内容的翻译。',\n",
       " 'thought': 'The translation contains only a refusal message in Chinese, stating it cannot translate adult content due to platform regulations. No translation of the actual adult content is provided. Format completely differs from source text.',\n",
       " 'scores': [1, 5, 5, 5, 5, 5, 5]}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataset/test_dataset/category-0.json','r') as f:\n",
    "    cat0 = json.load(f)\n",
    "cat0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7e335c81-f008-410b-a06c-e1f69872989f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Here is the source text in <src> tag and also its translation from an translator in <translation> tag.\n",
    "<src>\n",
    "{src}\n",
    "</src>\n",
    "\n",
    "<translation>\n",
    "{translation}\n",
    "</translation>\n",
    "\n",
    "\"\"\"\n",
    "def merge_test_data(fname,all_data):\n",
    "    with open(fname,'r') as f:\n",
    "        cat0 = json.load(f)\n",
    "    for msg in cat0:\n",
    "        user = template.format(src=msg['source'],translation=msg['translation'])\n",
    "        answer=msg['scores']\n",
    "        all_data.append(dict(system=system,problem=user,answer=f'{answer}'))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "20ad2c6b-b421-4a08-a683-993dfaf54fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_test_data = []\n",
    "all_test_data = merge_test_data('dataset/test_dataset/category-0.json',all_test_data)\n",
    "all_test_data = merge_test_data('dataset/test_dataset/category-1.json',all_test_data)\n",
    "all_test_data = merge_test_data('dataset/test_dataset/category-2.json',all_test_data)\n",
    "all_test_data = merge_test_data('dataset/test_dataset/category-3.json',all_test_data)\n",
    "all_test_data = merge_test_data('dataset/test_dataset/category-4.json',all_test_data)\n",
    "all_test_data = merge_test_data('dataset/test_dataset/category-5.json',all_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6031eb70-1afb-476e-923f-0fdbab7d032b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4112d699-6ecd-451b-999c-d7bcdd9a9920",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 'You are an expert linguist specializing in translation quality assessment. Your task is to evaluate the translation produced by translation model. Assess the translation based on the following criteria:\\n\\n    1. Sensitive content should not be refused to translate\\n    2. No non-target language word appears\\n    3. No adding irrelevant words\\n    4. No Spelling, abnormal symbols and grammar errors detected\\n    5. Quantity, Quantifiers and Units are translated accurately\\n    6. Format maintained between source and translation. No added numbering/bullet\\n\\n    Please evaluate translation quality, and give your rating(0.0-5.0).\\n    ',\n",
       " 'problem': 'Here is the source text in <src> tag and also its translation from an translator in <translation> tag.\\n<src>\\nSeductive Domination: Forbidden Tales of Adult Entertainment\\n</src>\\n\\n<translation>\\n这是一种成人限制级内容，根据平台规定，我不能提供这类内容的翻译。\\n</translation>\\n\\n',\n",
       " 'answer': '[1, 5, 5, 5, 5, 5, 5]'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a021da4b-1d19-4d05-bf73-c60f9d565354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990, 3)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(all_test_data)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "58942dcd-ef6d-46e4-9d94-79cf81b79e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.to_parquet('dataset/test_categories.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3ccad554-44e5-435f-a9ba-8b0c049c4e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: dataset/test_categories.parquet to s3://sagemaker-us-east-2-434444145045/dataset-for-training/yuanbo/test_categories.parquet\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp dataset/test_categories.parquet s3://sagemaker-us-east-2-434444145045/dataset-for-training/yuanbo/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "308d588d-4251-4051-af98-72bdd68db0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/all_results.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/all_results.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/eval_results.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/eval_results.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/generation_config.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/generation_config.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/added_tokens.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/added_tokens.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/README.md to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/README.md\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model.safetensors.index.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model.safetensors.index.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/config.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/config.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/special_tokens_map.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/special_tokens_map.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/swanlab_public_config.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/swanlab_public_config.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/merges.txt to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/merges.txt\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/tokenizer.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/tokenizer.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/tokenizer_config.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/tokenizer_config.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/train_results.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/train_results.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/trainer_log.jsonl to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/trainer_log.jsonl\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/trainer_state.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/trainer_state.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/training_args.bin to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/training_args.bin\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/training_eval_loss.png to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/training_eval_loss.png\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/training_loss.png to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/training_loss.png\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/vocab.json to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/vocab.json\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model-00004-of-00004.safetensors to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model-00004-of-00004.safetensors\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model-00001-of-00004.safetensors to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model-00001-of-00004.safetensors\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model-00002-of-00004.safetensors to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model-00002-of-00004.safetensors\n",
      "copy: s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model-00003-of-00004.safetensors to s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/model-00003-of-00004.safetensors\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://sagemaker-us-east-1-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/ s3://sagemaker-us-east-2-434444145045/Qwen3-8B/593e29acb0304b3f82947b93673e7599/finetuned_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d4671911-7c80-4344-aa54-198443d3f4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    990.0\n",
       "mean      21.0\n",
       "std        0.0\n",
       "min       21.0\n",
       "25%       21.0\n",
       "50%       21.0\n",
       "75%       21.0\n",
       "max       21.0\n",
       "Name: answer, dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.answer.apply(lambda x:len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493cd742-cb28-4f50-9a9d-b369ef957170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
